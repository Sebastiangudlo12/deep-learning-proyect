# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z26cFGjRRp9ASWNW3ns2EIrK5KT5BPaR
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from scikeras.wrappers import KerasRegressor  # Use scikeras for wrapping the Keras model

# Cargar el conjunto de datos
df = pd.read_csv('/media/Conjunto_servidores_p_blicos_20240826.csv')

# Eliminar las comas de la columna 'Asignación Básica Salarial' y convertirla a float
df['Asignación Básica Salarial'] = df['Asignación Básica Salarial'].str.replace(',', '').astype(float)

# Seleccionar las características de entrada y la etiqueta
X = df.drop(['Asignación Básica Salarial'], axis=1)
y = df['Asignación Básica Salarial']

# Eliminar las columnas que no se utilizarán en el modelo
X = X.drop(['Sexo'], axis=1)
X = X.drop(['ID Departamento de Nacimiento'], axis=1)
X = X.drop(['Departamento de Nacimiento'], axis=1)
X = X.drop(['Municipio de Nacimiento'], axis=1)
X = X.drop(['Dependencia Empleo Actual'], axis=1)
X = X.drop(['Tipo de Nombramiento'], axis=1)
X = X.drop(['Nivel Jerarquico Empleo'], axis=1)

# Convertir las columnas categóricas restantes en valores numéricos
X = pd.get_dummies(X, drop_first=True)

# Dividir el conjunto de datos en entrenamiento y prueba (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Función para crear el modelo
def create_model(optimizer='adam'):
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(1)
    ])
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_absolute_error'])
    return model

# Envuelve el modelo en un KerasRegressor
model = KerasRegressor(model=create_model, verbose=0)

# Definir los hiperparámetros a ajustar
param_grid = {
    'model__epochs': [50, 100, 200],
    'model__batch_size': [16, 32, 64],
    'model__optimizer': ['adam', 'sgd', 'rmsprop']
}

# Crear un objeto GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# Ajustar los hiperparámetros
grid_search.fit(X_train, y_train)

# Obtener los mejores hiperparámetros
best_params = grid_search.best_params_
print(best_params)

